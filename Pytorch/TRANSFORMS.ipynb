{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNbW8plLDLfCmnh16kwbXTk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Data does not always come in its final processed form that is required for training machine learning algorithms. We use transforms to perform some manipulation of the data and make it suitable for training.\n","\n","All TorchVision datasets have two parameters -`transform` to modify the features and `target_transform` to modify the labels - that accept callables containing the transformation logic. The torchvision.transforms module offers several commonly-used transforms out of the box.\n","\n","The FashionMNIST features are in PIL Image format, and the labels are integers. For training, we need the features as normalized tensors, and the labels as one-hot encoded tensors. To make these transformations, we use `ToTensor` and `Lambda`."],"metadata":{"id":"nwc8fdpGQk_X"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dAlumGwEP2in","executionInfo":{"status":"ok","timestamp":1699268144796,"user_tz":-480,"elapsed":6068,"user":{"displayName":"ManTang Wang","userId":"02060687760843430242"}},"outputId":"0e0177a1-3225-48d4-e274-43a156021776"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 26421880/26421880 [00:01<00:00, 14273709.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 29515/29515 [00:00<00:00, 270517.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4422102/4422102 [00:00<00:00, 5076081.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5148/5148 [00:00<00:00, 25136527.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n"]}],"source":["import torch\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor, Lambda\n","\n","ds = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor(),\n","    target_transform=Lambda(lambda y:torch.zeros(10,dtype=torch.float).scatter_(0,torch.tensor(y),value=1))\n",")"]},{"cell_type":"markdown","source":["其中，root 参数指定数据集存储的根目录，train 参数指定加载训练集数据还是测试集数据，download 参数指定是否需要下载数据集（如果数据集已经下载则可以设置为 False），`transform` 参数和 `target_transform` 参数分别指定在数据集加载时需要进行的图像变换和标签变换操作。\n","\n","这里，我们使用了 ToTensor 变换，它将 PIL 图像或 Numpy 数组转换为 PyTorch 张量，并将图像像素值归一化到 `[0, 1]` 范围内。同时，我们还使用了一个自定义的 Lambda 变换来将每个标签转换为一个长度为 10 的 one-hot 向量。具体来说，对于输入的标签 y，我们首先创建一个长度为 10、类型为浮点型的零向量，然后使用 `scatter_()` 方法将向量中第 y 个位置设为 1，最终返回转换后的标签向量。"],"metadata":{"id":"_50YTDhPSEtG"}}]}